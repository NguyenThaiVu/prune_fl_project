{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:  tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e: print(e)\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.keras import layers, models, datasets, utils\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, BatchNormalization, MaxPooling2D, Concatenate, Input, GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "\n",
    "from utils.model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (50000, 32, 32, 3)\n",
      "Shape of y_train: (50000, 10)\n",
      "Shape of x_test: (10000, 32, 32, 3)\n",
      "Shape of y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the images to a range of 0-1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = utils.to_categorical(y_train, 10)\n",
    "y_test = utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Shape of x_train: {x_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of x_test: {x_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module_naive(input_tensor, filters_1x1, filters_3x3, filters_5x5, idx_inception_block):\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3}\")(input_tensor)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3+1}\")(input_tensor)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3+2}\")(input_tensor)\n",
    "    max_pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_tensor)\n",
    "    \n",
    "    output = Concatenate(axis=-1)([conv_1x1, conv_3x3, conv_5x5, max_pool_proj])\n",
    "    return output\n",
    "\n",
    "def my_inception_module_naive(input_tensor, filters_1x1, filters_3x3, filters_5x5, idx_inception_block):\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3}\")(input_tensor)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3+1}\")(input_tensor)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3+2}\")(input_tensor)\n",
    "    \n",
    "    output = Concatenate(axis=-1)([conv_1x1, conv_3x3, conv_5x5])\n",
    "    return output\n",
    "\n",
    "def define_inception_model(input_shape, output_shape, list_number_filters=[64, 128, 32]):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    X = Conv2D(filters=32, kernel_size=3, strides=2, activation='relu', name=f'prunable_conv_0')(input_tensor)\n",
    "\n",
    "    for idx_inception_block in range(0, len(list_number_filters), 3):\n",
    "        list_current_filters = list_number_filters[idx_inception_block:idx_inception_block+3]\n",
    "        filters_1x1, filters_3x3, filters_5x5 = list_current_filters\n",
    "        X = my_inception_module_naive(X, filters_1x1, filters_3x3, filters_5x5, idx_inception_block)\n",
    "        X = BatchNormalization()(X)\n",
    "\n",
    "    X = Conv2D(filters=96, kernel_size=3, strides=2, activation='relu', name=f'prunable_conv_6')(X)\n",
    "    X = Conv2D(filters=96, kernel_size=3, strides=2, activation='relu', name=f'prunable_conv_7')(X)\n",
    "\n",
    "    # X = Flatten()(X)\n",
    "    X = GlobalAveragePooling2D()(X)\n",
    "\n",
    "    X = Dense(50, activation='relu')(X)\n",
    "    X = Dense(output_shape, activation='softmax')(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 244160\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "LIST_NUMBER_FILTERS = [16, 16, 16, 32, 32, 32]\n",
    "model = define_inception_model((32, 32, 3), 10, LIST_NUMBER_FILTERS)\n",
    "# model = Define_Simple_CNN_Model((32, 32, 3), 10, list_number_filters=[32, 64])\n",
    "\n",
    "print(f\"Number of params: {model.count_params()}\")\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_model(model, show_shapes=True, show_layer_names=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 1.8098 - accuracy: 0.3107 - val_loss: 1.5561 - val_accuracy: 0.4170\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.4371 - accuracy: 0.4697 - val_loss: 1.3058 - val_accuracy: 0.5240\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.2452 - accuracy: 0.5492 - val_loss: 1.1619 - val_accuracy: 0.5764\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.1241 - accuracy: 0.5953 - val_loss: 1.0740 - val_accuracy: 0.6123\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0352 - accuracy: 0.6273 - val_loss: 1.0076 - val_accuracy: 0.6458\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.9566 - accuracy: 0.6578 - val_loss: 1.0122 - val_accuracy: 0.6402\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.8929 - accuracy: 0.6809 - val_loss: 0.9282 - val_accuracy: 0.6698\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.8464 - accuracy: 0.6988 - val_loss: 0.9023 - val_accuracy: 0.6803\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.7884 - accuracy: 0.7179 - val_loss: 0.8720 - val_accuracy: 0.6965\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.7392 - accuracy: 0.7365 - val_loss: 0.8689 - val_accuracy: 0.6991\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6980 - accuracy: 0.7523 - val_loss: 0.8404 - val_accuracy: 0.7095\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6399 - accuracy: 0.7735 - val_loss: 0.8460 - val_accuracy: 0.7148\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.7894 - val_loss: 0.8989 - val_accuracy: 0.7034\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.5609 - accuracy: 0.8003 - val_loss: 0.8562 - val_accuracy: 0.7140\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.8192 - val_loss: 0.8695 - val_accuracy: 0.7169\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.8338 - val_loss: 0.8792 - val_accuracy: 0.7194\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4246 - accuracy: 0.8478 - val_loss: 0.9304 - val_accuracy: 0.7086\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8663 - val_loss: 0.9352 - val_accuracy: 0.7137\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8807 - val_loss: 0.9342 - val_accuracy: 0.7193\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8929 - val_loss: 1.0644 - val_accuracy: 0.7067\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 1.0802 - accuracy: 0.7068 - 378ms/epoch - 1ms/step\n",
      "Test accuracy: 0.7068\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
