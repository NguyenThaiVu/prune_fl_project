{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, I will train the FL with the Inception Architecture on the FEMNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 16:10:00.954394: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-24 16:10:00.954414: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-24 16:10:00.954438: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:  tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e: print(e)\n",
    "\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from config_celeb import *\n",
    "from utils.read_data_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.pruning_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Dataset Hyper-parameter\n",
    "DATASET_NAME = 'mnist'  # mnist\n",
    "\n",
    "IMAGE_DIMENSION = 28\n",
    "INPUT_SHAPE = (IMAGE_DIMENSION, IMAGE_DIMENSION, 1)\n",
    "\n",
    "OUPUT_SHAPE = 62 # \n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Model Hyper-parameter\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS = 'categorical_crossentropy'\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "LIST_NUMBER_FILTERS = [32, 16, 16, 16, 32, 32, 32, 96, 96]\n",
    "FILTER_SIZE = 5\n",
    "\n",
    "MODEL_TYPE = \"inception\" # ['vanilla_conv', 'resnet', 'inception']\n",
    "PATH_GLOBAL_MODEL = os.path.join(\"models\", \"global_model_inception_femnist_prune.h5\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Training Hyper-parameter\n",
    "NUM_ROUNDS = 500\n",
    "NUM_SELECTED_CLIENT = 10\n",
    "\n",
    "LOCAL_EPOCHS = 5\n",
    "LOCAL_BATCH_SIZE = 32\n",
    "\n",
    "MAX_PRUNED_ROUND = 100\n",
    "IS_STILL_PRUNE = True\n",
    "PRUNE_PATIENCE = 0\n",
    "MAX_PRUNE_PATIENCE = 3\n",
    "\n",
    "STD_THRESHOLD_PRUNE = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clients: 3400\n"
     ]
    }
   ],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(only_digits=False)\n",
    "\n",
    "num_clients = len(emnist_train.client_ids)\n",
    "print(f\"Number of clients: {num_clients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user: 3400\n"
     ]
    }
   ],
   "source": [
    "list_clients_data = Create_Clients_Data(emnist_train, DATASET_NAME)\n",
    "print(f\"Number of user: {len(list_clients_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image: (28, 28, 1)\n",
      "Max value of X: 1.0\n",
      "Min value of X: 0.011056924238801003\n",
      "Client = f0011_13\n",
      "Label = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_client = np.random.randint(0, 10)\n",
    "idx_sample = np.random.randint(0, 10)\n",
    "\n",
    "client_data = list_clients_data[idx_client]\n",
    "\n",
    "client_name = client_data['client_name']\n",
    "list_X = client_data['list_X']\n",
    "list_y = client_data['list_y']\n",
    "\n",
    "X = list_X[idx_sample]\n",
    "print(f\"Shape of image: {X.shape}\")\n",
    "print(f\"Max value of X: {X.max()}\")\n",
    "print(f\"Min value of X: {X.min()}\")\n",
    "\n",
    "y = list_y[idx_sample]\n",
    "\n",
    "print(f\"Client = {client_name}\")\n",
    "print(f\"Label = {y}\")\n",
    "plt.imshow(X, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Prepare val - test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X val: (38741, 28, 28, 1)\n",
      "Shape of y val: (38741, 62)\n",
      "Shape of X test: (38742, 28, 28, 1)\n",
      "Shape of y test: (38742, 62)\n"
     ]
    }
   ],
   "source": [
    "list_data_test = Create_Clients_Data(emnist_test)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for data_test in list_data_test:\n",
    "    X_test.append(data_test['list_X'])\n",
    "    y_test.append(data_test['list_y'])\n",
    "X_test = np.concatenate(X_test)\n",
    "y_test = np.concatenate(y_test)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Shape of X val: {X_val.shape}\")\n",
    "print(f\"Shape of y val: {y_val.shape}\")\n",
    "\n",
    "print(f\"Shape of X test: {X_test.shape}\")\n",
    "print(f\"Shape of y test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. FL Training\n",
    "\n",
    "## 2.1. Define components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_inception_module_naive(input_tensor, filters_1x1, filters_3x3, filters_5x5, idx_inception_block):\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3}\")(input_tensor)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3+1}\")(input_tensor)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3+2}\")(input_tensor)\n",
    "    output = Concatenate(axis=-1)([conv_1x1, conv_3x3, conv_5x5])\n",
    "    return output\n",
    "\n",
    "def define_inception_model(input_shape, output_shape, list_number_filters):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    X = Conv2D(filters=list_number_filters[0], kernel_size=3, strides=2, activation='relu', name=f'prunable_conv_0')(input_tensor)\n",
    "\n",
    "    for idx_inception_block in range(1, len(list_number_filters) - 2, 3):\n",
    "        list_current_filters = list_number_filters[idx_inception_block:idx_inception_block+3]\n",
    "        filters_1x1, filters_3x3, filters_5x5 = list_current_filters\n",
    "        X = my_inception_module_naive(X, filters_1x1, filters_3x3, filters_5x5, idx_inception_block-1)\n",
    "\n",
    "    X = Conv2D(filters=list_number_filters[-2], kernel_size=3, strides=2, activation='relu', name=f'prunable_conv_6')(X)\n",
    "    X = Conv2D(filters=list_number_filters[-1], kernel_size=3, strides=2, activation='relu', name=f'prunable_conv_7')(X)\n",
    "\n",
    "    # X = Flatten()(X)\n",
    "    X = GlobalAveragePooling2D()(X)\n",
    "\n",
    "    X = Dense(50, activation='relu')(X)\n",
    "    X = Dense(output_shape, activation='softmax')(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 246236\n",
      "Number of Conv2D layer: 9\n",
      "WARNING:tensorflow:From /home/necphy/miniconda3/envs/fl_env/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:5253: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/necphy/miniconda3/envs/fl_env/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:From /home/necphy/miniconda3/envs/fl_env/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:5253: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS of global model: 31010894\n",
      "=========================Options=============================\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "op: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "Conv2D                   30.96m float_ops (100.00%, 99.84%)\n",
      "BiasAdd                  33.70k float_ops (0.16%, 0.11%)\n",
      "MatMul                   15.80k float_ops (0.05%, 0.05%)\n",
      "Mean                       384 float_ops (0.00%, 0.00%)\n",
      "Softmax                    310 float_ops (0.00%, 0.00%)\n",
      "\n",
      "======================End of Report==========================\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " prunable_conv_0 (Conv2D)    (None, 13, 13, 32)           320       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " prunable_conv_1 (Conv2D)    (None, 13, 13, 16)           528       ['prunable_conv_0[0][0]']     \n",
      "                                                                                                  \n",
      " prunable_conv_2 (Conv2D)    (None, 13, 13, 16)           4624      ['prunable_conv_0[0][0]']     \n",
      "                                                                                                  \n",
      " prunable_conv_3 (Conv2D)    (None, 13, 13, 16)           12816     ['prunable_conv_0[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 13, 13, 48)           0         ['prunable_conv_1[0][0]',     \n",
      "                                                                     'prunable_conv_2[0][0]',     \n",
      "                                                                     'prunable_conv_3[0][0]']     \n",
      "                                                                                                  \n",
      " prunable_conv_10 (Conv2D)   (None, 13, 13, 32)           1568      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " prunable_conv_11 (Conv2D)   (None, 13, 13, 32)           13856     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " prunable_conv_12 (Conv2D)   (None, 13, 13, 32)           38432     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 13, 13, 96)           0         ['prunable_conv_10[0][0]',    \n",
      " )                                                                   'prunable_conv_11[0][0]',    \n",
      "                                                                     'prunable_conv_12[0][0]']    \n",
      "                                                                                                  \n",
      " prunable_conv_6 (Conv2D)    (None, 6, 6, 96)             83040     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " prunable_conv_7 (Conv2D)    (None, 2, 2, 96)             83040     ['prunable_conv_6[0][0]']     \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 96)                   0         ['prunable_conv_7[0][0]']     \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 50)                   4850      ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 62)                   3162      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 246236 (961.86 KB)\n",
      "Trainable params: 246236 (961.86 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "global_model = define_inception_model(INPUT_SHAPE, OUPUT_SHAPE, LIST_NUMBER_FILTERS)\n",
    "global_model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics = METRICS)\n",
    "print(f\"Number of params: {global_model.count_params()}\")\n",
    "\n",
    "num_conv_layers = Count_Conv2d_Layers(global_model)\n",
    "print(f\"Number of Conv2D layer: {num_conv_layers}\")\n",
    "plot_model(global_model, to_file=os.path.join('images', f'{MODEL_TYPE}.png'), show_shapes=True, show_layer_names=True);\n",
    "global_model.save(PATH_GLOBAL_MODEL)\n",
    "\n",
    "flops = get_flops_keras_model(global_model)\n",
    "print(f\"FLOPS of global model: {flops}\")\n",
    "\n",
    "global_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. FL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model, optimizer, loss_func, metrics, std_threshold=3.0):\n",
    "    \"\"\"\n",
    "    This function take input as model and perform model pruning to return the pruned filters CNN model.\n",
    "\n",
    "    * Parameters:\n",
    "        model (keras model): input model.\n",
    "        optimizer (keras optimizer).\n",
    "        loss_func (keras loss function).\n",
    "        metrics (keras metrics)\n",
    "        std_threshold (integer): threshold to prune filters.\n",
    "\n",
    "    * Return:\n",
    "        model (keras model) -- the pruned filters model.\n",
    "    \"\"\"\n",
    "\n",
    "    global IS_STILL_PRUNE\n",
    "    global PRUNE_PATIENCE\n",
    "    before_prune_params = model.count_params()\n",
    "\n",
    "    list_number_filters = []\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Conv2D) and layer.name != 'classifier' and 'prunable_conv' in layer.name:\n",
    "            weights = layer.get_weights()[0]\n",
    "            pruned_filter = Apply_Pruning_Filter(weights, std_threshold)\n",
    "            pruned_number_filter = pruned_filter.shape[-1]\n",
    "\n",
    "            if pruned_number_filter <= 0:\n",
    "                pruned_number_filter = 1\n",
    "            list_number_filters.append(pruned_number_filter)\n",
    "\n",
    "    new_model = define_inception_model(input_shape=model.input_shape[1:], output_shape=model.output_shape[1], list_number_filters=list_number_filters)\n",
    "    new_model_params = new_model.count_params()\n",
    "    print(f\"list_number_filters: {list_number_filters}\")\n",
    "    print(f\"before_prune_params: {before_prune_params}\")\n",
    "    print(f\"new_model_params: {new_model_params}\")\n",
    "\n",
    "    if before_prune_params > new_model_params:\n",
    "        PRUNE_PATIENCE = 0\n",
    "        print(f\"--- [INFO] This round PRUNE filter ---\")\n",
    "        new_model.compile(optimizer=optimizer, loss=loss_func, metrics=metrics)\n",
    "        return new_model\n",
    "    else:\n",
    "        PRUNE_PATIENCE += 1\n",
    "        print(f\"--- [INFO] This round NOT prune filter ---\")\n",
    "        if PRUNE_PATIENCE >= MAX_PRUNE_PATIENCE:\n",
    "            IS_STILL_PRUNE = False\n",
    "            print(f\"===== [INFO] Stop prune here! =====\")\n",
    "            print(f\"Final params: {before_prune_params}\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Round 0\n",
      "Val loss: 3.9626057147979736, Val accuracy: 0.049224335700273514\n",
      "\n",
      " [INFO] Round 1\n",
      "list_number_filters: [30, 16, 16, 16, 31, 32, 32, 95, 94]\n",
      "before_prune_params: 246236\n",
      "new_model_params: 240651\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 2\n",
      "list_number_filters: [29, 16, 16, 16, 31, 32, 32, 94, 93]\n",
      "before_prune_params: 240651\n",
      "new_model_params: 237482\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 3\n",
      "list_number_filters: [29, 16, 16, 16, 30, 31, 31, 92, 92]\n",
      "before_prune_params: 237482\n",
      "new_model_params: 229050\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 4\n",
      "list_number_filters: [29, 16, 16, 16, 30, 31, 31, 90, 90]\n",
      "before_prune_params: 229050\n",
      "new_model_params: 224014\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 5\n",
      "list_number_filters: [29, 16, 16, 15, 29, 30, 31, 89, 89]\n",
      "before_prune_params: 224014\n",
      "new_model_params: 217639\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 6\n",
      "list_number_filters: [29, 16, 16, 15, 28, 30, 30, 87, 89]\n",
      "before_prune_params: 217639\n",
      "new_model_params: 211625\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 7\n",
      "list_number_filters: [29, 16, 16, 15, 28, 30, 30, 86, 87]\n",
      "before_prune_params: 211625\n",
      "new_model_params: 208381\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 8\n",
      "list_number_filters: [29, 16, 16, 15, 28, 30, 30, 86, 86]\n",
      "before_prune_params: 208381\n",
      "new_model_params: 207556\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 9\n",
      "list_number_filters: [29, 15, 16, 15, 28, 30, 29, 84, 86]\n",
      "before_prune_params: 207556\n",
      "new_model_params: 201437\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 10\n",
      "list_number_filters: [28, 15, 16, 15, 28, 30, 29, 83, 86]\n",
      "before_prune_params: 201437\n",
      "new_model_params: 199335\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 11\n",
      "list_number_filters: [28, 15, 16, 15, 28, 29, 29, 81, 86]\n",
      "before_prune_params: 199335\n",
      "new_model_params: 195075\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 12\n",
      "list_number_filters: [28, 14, 16, 15, 28, 29, 28, 79, 86]\n",
      "before_prune_params: 195075\n",
      "new_model_params: 189097\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 13\n",
      "list_number_filters: [28, 14, 16, 15, 27, 29, 28, 77, 84]\n",
      "before_prune_params: 189097\n",
      "new_model_params: 183790\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 14\n",
      "list_number_filters: [27, 14, 16, 15, 27, 29, 28, 77, 83]\n",
      "before_prune_params: 183790\n",
      "new_model_params: 182503\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 15\n",
      "list_number_filters: [26, 14, 16, 15, 27, 29, 28, 76, 82]\n",
      "before_prune_params: 182503\n",
      "new_model_params: 179721\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 16\n",
      "list_number_filters: [25, 14, 16, 15, 27, 29, 28, 76, 82]\n",
      "before_prune_params: 179721\n",
      "new_model_params: 179178\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 17\n",
      "list_number_filters: [25, 14, 16, 15, 26, 29, 27, 75, 82]\n",
      "before_prune_params: 179178\n",
      "new_model_params: 175161\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 18\n",
      "list_number_filters: [25, 14, 16, 15, 26, 28, 27, 75, 81]\n",
      "before_prune_params: 175161\n",
      "new_model_params: 173354\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 19\n",
      "list_number_filters: [25, 14, 16, 15, 26, 28, 27, 74, 81]\n",
      "before_prune_params: 173354\n",
      "new_model_params: 171895\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 20\n",
      "list_number_filters: [25, 14, 16, 15, 25, 27, 27, 74, 81]\n",
      "before_prune_params: 171895\n",
      "new_model_params: 170111\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "Val loss: 3.9742140769958496, Val accuracy: 0.05387057736515999\n",
      "\n",
      " [INFO] Round 21\n",
      "list_number_filters: [25, 13, 16, 15, 25, 27, 26, 72, 80]\n",
      "before_prune_params: 170111\n",
      "new_model_params: 163812\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 22\n",
      "list_number_filters: [24, 13, 16, 15, 25, 26, 26, 71, 79]\n",
      "before_prune_params: 163812\n",
      "new_model_params: 160121\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 23\n",
      "list_number_filters: [24, 12, 16, 15, 25, 25, 26, 70, 77]\n",
      "before_prune_params: 160121\n",
      "new_model_params: 155402\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 24\n",
      "list_number_filters: [24, 11, 16, 15, 25, 24, 24, 69, 76]\n",
      "before_prune_params: 155402\n",
      "new_model_params: 148083\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 25\n",
      "list_number_filters: [24, 11, 16, 15, 25, 24, 24, 69, 76]\n",
      "before_prune_params: 148083\n",
      "new_model_params: 148083\n",
      "--- [INFO] This round NOT prune filter ---\n",
      "\n",
      " [INFO] Round 26\n",
      "list_number_filters: [24, 11, 16, 15, 25, 24, 24, 69, 76]\n",
      "before_prune_params: 148083\n",
      "new_model_params: 148083\n",
      "--- [INFO] This round NOT prune filter ---\n",
      "\n",
      " [INFO] Round 27\n",
      "list_number_filters: [24, 11, 16, 15, 25, 24, 24, 69, 75]\n",
      "before_prune_params: 148083\n",
      "new_model_params: 147411\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 28\n",
      "list_number_filters: [24, 11, 16, 15, 25, 23, 24, 67, 74]\n",
      "before_prune_params: 147411\n",
      "new_model_params: 143109\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 29\n",
      "list_number_filters: [24, 11, 16, 15, 25, 23, 24, 66, 74]\n",
      "before_prune_params: 143109\n",
      "new_model_params: 141794\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 30\n",
      "list_number_filters: [24, 11, 16, 15, 25, 22, 23, 65, 74]\n",
      "before_prune_params: 141794\n",
      "new_model_params: 137879\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 31\n",
      "list_number_filters: [24, 11, 16, 15, 25, 21, 23, 65, 72]\n",
      "before_prune_params: 137879\n",
      "new_model_params: 135643\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 32\n",
      "list_number_filters: [24, 11, 16, 15, 25, 21, 23, 64, 72]\n",
      "before_prune_params: 135643\n",
      "new_model_params: 134373\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 33\n",
      "list_number_filters: [24, 11, 16, 15, 25, 20, 23, 63, 71]\n",
      "before_prune_params: 134373\n",
      "new_model_params: 131539\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 34\n",
      "list_number_filters: [24, 11, 16, 15, 25, 20, 23, 62, 71]\n",
      "before_prune_params: 131539\n",
      "new_model_params: 130287\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 35\n",
      "list_number_filters: [23, 11, 16, 15, 24, 20, 23, 61, 70]\n",
      "before_prune_params: 130287\n",
      "new_model_params: 127303\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 36\n",
      "list_number_filters: [23, 11, 16, 15, 24, 20, 23, 61, 70]\n",
      "before_prune_params: 127303\n",
      "new_model_params: 127303\n",
      "--- [INFO] This round NOT prune filter ---\n",
      "\n",
      " [INFO] Round 37\n",
      "list_number_filters: [23, 11, 16, 15, 24, 20, 23, 61, 70]\n",
      "before_prune_params: 127303\n",
      "new_model_params: 127303\n",
      "--- [INFO] This round NOT prune filter ---\n",
      "\n",
      " [INFO] Round 38\n",
      "list_number_filters: [23, 11, 15, 15, 24, 20, 23, 61, 70]\n",
      "before_prune_params: 127303\n",
      "new_model_params: 126316\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 39\n",
      "list_number_filters: [23, 11, 15, 15, 24, 20, 23, 60, 69]\n",
      "before_prune_params: 126316\n",
      "new_model_params: 124491\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 40\n",
      "list_number_filters: [22, 11, 15, 15, 24, 20, 23, 58, 67]\n",
      "before_prune_params: 124491\n",
      "new_model_params: 120364\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "Val loss: 4.010552883148193, Val accuracy: 0.04881133511662483\n",
      "\n",
      " [INFO] Round 41\n",
      "list_number_filters: [22, 11, 15, 15, 23, 20, 23, 58, 67]\n",
      "before_prune_params: 120364\n",
      "new_model_params: 119800\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 42\n",
      "list_number_filters: [22, 11, 15, 15, 23, 20, 23, 57, 66]\n",
      "before_prune_params: 119800\n",
      "new_model_params: 118038\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 43\n",
      "list_number_filters: [22, 11, 15, 15, 23, 19, 23, 57, 65]\n",
      "before_prune_params: 118038\n",
      "new_model_params: 116591\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 44\n",
      "list_number_filters: [22, 11, 15, 15, 23, 19, 23, 57, 65]\n",
      "before_prune_params: 116591\n",
      "new_model_params: 116591\n",
      "--- [INFO] This round NOT prune filter ---\n",
      "\n",
      " [INFO] Round 45\n",
      "list_number_filters: [22, 11, 15, 14, 23, 19, 23, 57, 65]\n",
      "before_prune_params: 116591\n",
      "new_model_params: 115271\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 46\n",
      "list_number_filters: [22, 11, 15, 14, 22, 19, 23, 57, 63]\n",
      "before_prune_params: 115271\n",
      "new_model_params: 113589\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 47\n",
      "list_number_filters: [22, 11, 15, 14, 22, 18, 23, 57, 62]\n",
      "before_prune_params: 113589\n",
      "new_model_params: 112151\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 48\n",
      "list_number_filters: [22, 11, 15, 14, 22, 17, 22, 56, 62]\n",
      "before_prune_params: 112151\n",
      "new_model_params: 108655\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 49\n",
      "list_number_filters: [22, 11, 15, 14, 22, 17, 21, 55, 62]\n",
      "before_prune_params: 108655\n",
      "new_model_params: 106051\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 50\n",
      "list_number_filters: [22, 11, 15, 14, 22, 17, 21, 54, 60]\n",
      "before_prune_params: 106051\n",
      "new_model_params: 103878\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 51\n",
      "list_number_filters: [22, 11, 15, 13, 22, 17, 21, 53, 60]\n",
      "before_prune_params: 103878\n",
      "new_model_params: 101546\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 52\n",
      "list_number_filters: [22, 11, 15, 13, 22, 17, 21, 52, 59]\n",
      "before_prune_params: 101546\n",
      "new_model_params: 99946\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 53\n",
      "list_number_filters: [22, 11, 15, 13, 22, 17, 20, 51, 59]\n",
      "before_prune_params: 99946\n",
      "new_model_params: 97439\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 54\n",
      "list_number_filters: [22, 11, 15, 13, 21, 17, 20, 51, 57]\n",
      "before_prune_params: 97439\n",
      "new_model_params: 95920\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 55\n",
      "list_number_filters: [22, 11, 15, 13, 21, 17, 20, 51, 56]\n",
      "before_prune_params: 95920\n",
      "new_model_params: 95410\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 56\n",
      "list_number_filters: [22, 11, 14, 13, 21, 17, 20, 51, 55]\n",
      "before_prune_params: 95410\n",
      "new_model_params: 94027\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 57\n",
      "list_number_filters: [22, 11, 13, 13, 20, 17, 20, 51, 55]\n",
      "before_prune_params: 94027\n",
      "new_model_params: 92657\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 58\n",
      "list_number_filters: [22, 11, 13, 13, 20, 17, 19, 51, 55]\n",
      "before_prune_params: 92657\n",
      "new_model_params: 91272\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 59\n",
      "list_number_filters: [22, 11, 13, 13, 20, 17, 19, 50, 55]\n",
      "before_prune_params: 91272\n",
      "new_model_params: 90272\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 60\n",
      "list_number_filters: [22, 11, 13, 13, 20, 17, 19, 50, 54]\n",
      "before_prune_params: 90272\n",
      "new_model_params: 89771\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "Val loss: 3.995171546936035, Val accuracy: 0.05074727162718773\n",
      "\n",
      " [INFO] Round 61\n",
      "list_number_filters: [22, 11, 13, 13, 20, 16, 18, 49, 53]\n",
      "before_prune_params: 89771\n",
      "new_model_params: 86146\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 62\n",
      "list_number_filters: [21, 11, 13, 13, 20, 16, 18, 48, 53]\n",
      "before_prune_params: 86146\n",
      "new_model_params: 84719\n",
      "--- [INFO] This round PRUNE filter ---\n",
      "\n",
      " [INFO] Round 63\n",
      "list_number_filters: [21, 11, 13, 13, 20, 16, 18, 48, 53]\n",
      "before_prune_params: 84719\n",
      "new_model_params: 84719\n",
      "--- [INFO] This round NOT prune filter ---\n",
      "\n",
      " [INFO] Round 64\n",
      "list_number_filters: [21, 11, 13, 13, 20, 16, 18, 48, 53]\n",
      "before_prune_params: 84719\n",
      "new_model_params: 84719\n",
      "--- [INFO] This round NOT prune filter ---\n",
      "\n",
      " [INFO] Round 65\n",
      "list_number_filters: [21, 11, 13, 13, 20, 16, 18, 48, 53]\n",
      "before_prune_params: 84719\n",
      "new_model_params: 84719\n",
      "--- [INFO] This round NOT prune filter ---\n",
      "===== [INFO] Stop prune here! =====\n",
      "Final params: 84719\n",
      "\n",
      " [INFO] Round 66\n",
      "\n",
      " [INFO] Round 67\n",
      "\n",
      " [INFO] Round 68\n",
      "\n",
      " [INFO] Round 69\n",
      "\n",
      " [INFO] Round 70\n",
      "\n",
      " [INFO] Round 71\n",
      "\n",
      " [INFO] Round 72\n",
      "\n",
      " [INFO] Round 73\n",
      "\n",
      " [INFO] Round 74\n",
      "\n",
      " [INFO] Round 75\n",
      "\n",
      " [INFO] Round 76\n",
      "\n",
      " [INFO] Round 77\n",
      "\n",
      " [INFO] Round 78\n",
      "\n",
      " [INFO] Round 79\n",
      "\n",
      " [INFO] Round 80\n",
      "Val loss: 2.173413038253784, Val accuracy: 0.49164968729019165\n",
      "\n",
      " [INFO] Round 81\n",
      "\n",
      " [INFO] Round 82\n",
      "\n",
      " [INFO] Round 83\n",
      "\n",
      " [INFO] Round 84\n",
      "\n",
      " [INFO] Round 85\n",
      "\n",
      " [INFO] Round 86\n",
      "\n",
      " [INFO] Round 87\n",
      "\n",
      " [INFO] Round 88\n",
      "\n",
      " [INFO] Round 89\n",
      "\n",
      " [INFO] Round 90\n",
      "\n",
      " [INFO] Round 91\n",
      "\n",
      " [INFO] Round 92\n",
      "\n",
      " [INFO] Round 93\n",
      "\n",
      " [INFO] Round 94\n",
      "\n",
      " [INFO] Round 95\n",
      "\n",
      " [INFO] Round 96\n",
      "\n",
      " [INFO] Round 97\n",
      "\n",
      " [INFO] Round 98\n",
      "\n",
      " [INFO] Round 99\n",
      "\n",
      " [INFO] Round 100\n",
      "Val loss: 1.5152486562728882, Val accuracy: 0.6099997162818909\n",
      "\n",
      " [INFO] Round 101\n",
      "\n",
      " [INFO] Round 102\n",
      "\n",
      " [INFO] Round 103\n",
      "\n",
      " [INFO] Round 104\n",
      "\n",
      " [INFO] Round 105\n",
      "\n",
      " [INFO] Round 106\n",
      "\n",
      " [INFO] Round 107\n",
      "\n",
      " [INFO] Round 108\n",
      "\n",
      " [INFO] Round 109\n",
      "\n",
      " [INFO] Round 110\n",
      "\n",
      " [INFO] Round 111\n",
      "\n",
      " [INFO] Round 112\n",
      "\n",
      " [INFO] Round 113\n",
      "\n",
      " [INFO] Round 114\n",
      "\n",
      " [INFO] Round 115\n",
      "\n",
      " [INFO] Round 116\n",
      "\n",
      " [INFO] Round 117\n",
      "\n",
      " [INFO] Round 118\n",
      "\n",
      " [INFO] Round 119\n",
      "\n",
      " [INFO] Round 120\n",
      "Val loss: 1.2825746536254883, Val accuracy: 0.6710978150367737\n",
      "\n",
      " [INFO] Round 121\n",
      "\n",
      " [INFO] Round 122\n",
      "\n",
      " [INFO] Round 123\n",
      "\n",
      " [INFO] Round 124\n",
      "\n",
      " [INFO] Round 125\n",
      "\n",
      " [INFO] Round 126\n",
      "\n",
      " [INFO] Round 127\n",
      "\n",
      " [INFO] Round 128\n",
      "\n",
      " [INFO] Round 129\n",
      "\n",
      " [INFO] Round 130\n",
      "\n",
      " [INFO] Round 131\n",
      "\n",
      " [INFO] Round 132\n",
      "\n",
      " [INFO] Round 133\n",
      "\n",
      " [INFO] Round 134\n",
      "\n",
      " [INFO] Round 135\n",
      "\n",
      " [INFO] Round 136\n",
      "\n",
      " [INFO] Round 137\n",
      "\n",
      " [INFO] Round 138\n",
      "\n",
      " [INFO] Round 139\n",
      "\n",
      " [INFO] Round 140\n",
      "Val loss: 1.264916181564331, Val accuracy: 0.6758214831352234\n",
      "\n",
      " [INFO] Round 141\n",
      "\n",
      " [INFO] Round 142\n",
      "\n",
      " [INFO] Round 143\n",
      "\n",
      " [INFO] Round 144\n",
      "\n",
      " [INFO] Round 145\n",
      "\n",
      " [INFO] Round 146\n",
      "\n",
      " [INFO] Round 147\n",
      "\n",
      " [INFO] Round 148\n",
      "\n",
      " [INFO] Round 149\n",
      "\n",
      " [INFO] Round 150\n",
      "\n",
      " [INFO] Round 151\n",
      "\n",
      " [INFO] Round 152\n",
      "\n",
      " [INFO] Round 153\n",
      "\n",
      " [INFO] Round 154\n",
      "\n",
      " [INFO] Round 155\n",
      "\n",
      " [INFO] Round 156\n",
      "\n",
      " [INFO] Round 157\n",
      "\n",
      " [INFO] Round 158\n",
      "\n",
      " [INFO] Round 159\n",
      "\n",
      " [INFO] Round 160\n",
      "Val loss: 1.1038726568222046, Val accuracy: 0.7104101777076721\n",
      "\n",
      " [INFO] Round 161\n",
      "\n",
      " [INFO] Round 162\n",
      "\n",
      " [INFO] Round 163\n",
      "\n",
      " [INFO] Round 164\n",
      "\n",
      " [INFO] Round 165\n",
      "\n",
      " [INFO] Round 166\n",
      "\n",
      " [INFO] Round 167\n",
      "\n",
      " [INFO] Round 168\n",
      "\n",
      " [INFO] Round 169\n",
      "\n",
      " [INFO] Round 170\n",
      "\n",
      " [INFO] Round 171\n",
      "\n",
      " [INFO] Round 172\n",
      "\n",
      " [INFO] Round 173\n",
      "\n",
      " [INFO] Round 174\n",
      "\n",
      " [INFO] Round 175\n",
      "\n",
      " [INFO] Round 176\n",
      "\n",
      " [INFO] Round 177\n",
      "\n",
      " [INFO] Round 178\n",
      "\n",
      " [INFO] Round 179\n",
      "\n",
      " [INFO] Round 180\n",
      "Val loss: 1.125598669052124, Val accuracy: 0.7258718013763428\n",
      "\n",
      " [INFO] Round 181\n",
      "\n",
      " [INFO] Round 182\n",
      "\n",
      " [INFO] Round 183\n",
      "\n",
      " [INFO] Round 184\n",
      "\n",
      " [INFO] Round 185\n",
      "\n",
      " [INFO] Round 186\n",
      "\n",
      " [INFO] Round 187\n",
      "\n",
      " [INFO] Round 188\n",
      "\n",
      " [INFO] Round 189\n",
      "\n",
      " [INFO] Round 190\n",
      "\n",
      " [INFO] Round 191\n",
      "\n",
      " [INFO] Round 192\n",
      "\n",
      " [INFO] Round 193\n",
      "\n",
      " [INFO] Round 194\n",
      "\n",
      " [INFO] Round 195\n",
      "\n",
      " [INFO] Round 196\n",
      "\n",
      " [INFO] Round 197\n",
      "\n",
      " [INFO] Round 198\n",
      "\n",
      " [INFO] Round 199\n",
      "\n",
      " [INFO] Round 200\n",
      "Val loss: 0.9189757108688354, Val accuracy: 0.7522521615028381\n",
      "\n",
      " [INFO] Round 201\n",
      "\n",
      " [INFO] Round 202\n",
      "\n",
      " [INFO] Round 203\n",
      "\n",
      " [INFO] Round 204\n",
      "\n",
      " [INFO] Round 205\n",
      "\n",
      " [INFO] Round 206\n",
      "\n",
      " [INFO] Round 207\n",
      "\n",
      " [INFO] Round 208\n",
      "\n",
      " [INFO] Round 209\n",
      "\n",
      " [INFO] Round 210\n",
      "\n",
      " [INFO] Round 211\n",
      "\n",
      " [INFO] Round 212\n",
      "\n",
      " [INFO] Round 213\n",
      "\n",
      " [INFO] Round 214\n",
      "\n",
      " [INFO] Round 215\n",
      "\n",
      " [INFO] Round 216\n",
      "\n",
      " [INFO] Round 217\n",
      "\n",
      " [INFO] Round 218\n",
      "\n",
      " [INFO] Round 219\n",
      "\n",
      " [INFO] Round 220\n",
      "Val loss: 0.995496928691864, Val accuracy: 0.7279626131057739\n",
      "\n",
      " [INFO] Round 221\n",
      "\n",
      " [INFO] Round 222\n",
      "\n",
      " [INFO] Round 223\n",
      "\n",
      " [INFO] Round 224\n",
      "\n",
      " [INFO] Round 225\n",
      "\n",
      " [INFO] Round 226\n",
      "\n",
      " [INFO] Round 227\n",
      "\n",
      " [INFO] Round 228\n",
      "\n",
      " [INFO] Round 229\n",
      "\n",
      " [INFO] Round 230\n",
      "\n",
      " [INFO] Round 231\n",
      "\n",
      " [INFO] Round 232\n",
      "\n",
      " [INFO] Round 233\n",
      "\n",
      " [INFO] Round 234\n",
      "\n",
      " [INFO] Round 235\n",
      "\n",
      " [INFO] Round 236\n",
      "\n",
      " [INFO] Round 237\n",
      "\n",
      " [INFO] Round 238\n",
      "\n",
      " [INFO] Round 239\n",
      "\n",
      " [INFO] Round 240\n",
      "Val loss: 0.9011009335517883, Val accuracy: 0.7586020231246948\n",
      "\n",
      " [INFO] Round 241\n",
      "\n",
      " [INFO] Round 242\n",
      "\n",
      " [INFO] Round 243\n",
      "\n",
      " [INFO] Round 244\n",
      "\n",
      " [INFO] Round 245\n",
      "\n",
      " [INFO] Round 246\n",
      "\n",
      " [INFO] Round 247\n",
      "\n",
      " [INFO] Round 248\n",
      "\n",
      " [INFO] Round 249\n",
      "\n",
      " [INFO] Round 250\n",
      "\n",
      " [INFO] Round 251\n",
      "\n",
      " [INFO] Round 252\n",
      "\n",
      " [INFO] Round 253\n",
      "\n",
      " [INFO] Round 254\n",
      "\n",
      " [INFO] Round 255\n",
      "\n",
      " [INFO] Round 256\n",
      "\n",
      " [INFO] Round 257\n",
      "\n",
      " [INFO] Round 258\n",
      "\n",
      " [INFO] Round 259\n",
      "\n",
      " [INFO] Round 260\n",
      "Val loss: 0.8458121418952942, Val accuracy: 0.7674298286437988\n",
      "\n",
      " [INFO] Round 261\n",
      "\n",
      " [INFO] Round 262\n",
      "\n",
      " [INFO] Round 263\n",
      "\n",
      " [INFO] Round 264\n",
      "\n",
      " [INFO] Round 265\n",
      "\n",
      " [INFO] Round 266\n",
      "\n",
      " [INFO] Round 267\n",
      "\n",
      " [INFO] Round 268\n",
      "\n",
      " [INFO] Round 269\n",
      "\n",
      " [INFO] Round 270\n",
      "\n",
      " [INFO] Round 271\n",
      "\n",
      " [INFO] Round 272\n",
      "\n",
      " [INFO] Round 273\n",
      "\n",
      " [INFO] Round 274\n",
      "\n",
      " [INFO] Round 275\n",
      "\n",
      " [INFO] Round 276\n",
      "\n",
      " [INFO] Round 277\n",
      "\n",
      " [INFO] Round 278\n",
      "\n",
      " [INFO] Round 279\n",
      "\n",
      " [INFO] Round 280\n",
      "Val loss: 0.8387565016746521, Val accuracy: 0.7764384150505066\n",
      "\n",
      " [INFO] Round 281\n",
      "\n",
      " [INFO] Round 282\n",
      "\n",
      " [INFO] Round 283\n",
      "\n",
      " [INFO] Round 284\n",
      "\n",
      " [INFO] Round 285\n",
      "\n",
      " [INFO] Round 286\n",
      "\n",
      " [INFO] Round 287\n",
      "\n",
      " [INFO] Round 288\n",
      "\n",
      " [INFO] Round 289\n",
      "\n",
      " [INFO] Round 290\n",
      "\n",
      " [INFO] Round 291\n",
      "\n",
      " [INFO] Round 292\n",
      "\n",
      " [INFO] Round 293\n",
      "\n",
      " [INFO] Round 294\n",
      "\n",
      " [INFO] Round 295\n",
      "\n",
      " [INFO] Round 296\n",
      "\n",
      " [INFO] Round 297\n",
      "\n",
      " [INFO] Round 298\n",
      "\n",
      " [INFO] Round 299\n",
      "\n",
      " [INFO] Round 300\n",
      "Val loss: 0.761481523513794, Val accuracy: 0.7831496596336365\n",
      "\n",
      " [INFO] Round 301\n",
      "\n",
      " [INFO] Round 302\n",
      "\n",
      " [INFO] Round 303\n",
      "\n",
      " [INFO] Round 304\n",
      "\n",
      " [INFO] Round 305\n",
      "\n",
      " [INFO] Round 306\n",
      "\n",
      " [INFO] Round 307\n",
      "\n",
      " [INFO] Round 308\n",
      "\n",
      " [INFO] Round 309\n",
      "\n",
      " [INFO] Round 310\n",
      "\n",
      " [INFO] Round 311\n",
      "\n",
      " [INFO] Round 312\n",
      "\n",
      " [INFO] Round 313\n",
      "\n",
      " [INFO] Round 314\n",
      "\n",
      " [INFO] Round 315\n",
      "\n",
      " [INFO] Round 316\n",
      "\n",
      " [INFO] Round 317\n",
      "\n",
      " [INFO] Round 318\n",
      "\n",
      " [INFO] Round 319\n",
      "\n",
      " [INFO] Round 320\n",
      "Val loss: 0.8354235887527466, Val accuracy: 0.7696239352226257\n",
      "\n",
      " [INFO] Round 321\n",
      "\n",
      " [INFO] Round 322\n",
      "\n",
      " [INFO] Round 323\n",
      "\n",
      " [INFO] Round 324\n",
      "\n",
      " [INFO] Round 325\n",
      "\n",
      " [INFO] Round 326\n",
      "\n",
      " [INFO] Round 327\n",
      "\n",
      " [INFO] Round 328\n",
      "\n",
      " [INFO] Round 329\n",
      "\n",
      " [INFO] Round 330\n",
      "\n",
      " [INFO] Round 331\n",
      "\n",
      " [INFO] Round 332\n",
      "\n",
      " [INFO] Round 333\n",
      "\n",
      " [INFO] Round 334\n",
      "\n",
      " [INFO] Round 335\n",
      "\n",
      " [INFO] Round 336\n",
      "\n",
      " [INFO] Round 337\n",
      "\n",
      " [INFO] Round 338\n",
      "\n",
      " [INFO] Round 339\n",
      "\n",
      " [INFO] Round 340\n",
      "Val loss: 0.8016156554222107, Val accuracy: 0.7849823236465454\n",
      "\n",
      " [INFO] Round 341\n",
      "\n",
      " [INFO] Round 342\n",
      "\n",
      " [INFO] Round 343\n",
      "\n",
      " [INFO] Round 344\n",
      "\n",
      " [INFO] Round 345\n",
      "\n",
      " [INFO] Round 346\n",
      "\n",
      " [INFO] Round 347\n",
      "\n",
      " [INFO] Round 348\n",
      "\n",
      " [INFO] Round 349\n",
      "\n",
      " [INFO] Round 350\n",
      "\n",
      " [INFO] Round 351\n",
      "\n",
      " [INFO] Round 352\n",
      "\n",
      " [INFO] Round 353\n",
      "\n",
      " [INFO] Round 354\n",
      "\n",
      " [INFO] Round 355\n",
      "\n",
      " [INFO] Round 356\n",
      "\n",
      " [INFO] Round 357\n",
      "\n",
      " [INFO] Round 358\n",
      "\n",
      " [INFO] Round 359\n",
      "\n",
      " [INFO] Round 360\n",
      "Val loss: 0.7679609656333923, Val accuracy: 0.7981724739074707\n",
      "\n",
      " [INFO] Round 361\n",
      "\n",
      " [INFO] Round 362\n",
      "\n",
      " [INFO] Round 363\n",
      "\n",
      " [INFO] Round 364\n",
      "\n",
      " [INFO] Round 365\n",
      "\n",
      " [INFO] Round 366\n",
      "\n",
      " [INFO] Round 367\n",
      "\n",
      " [INFO] Round 368\n",
      "\n",
      " [INFO] Round 369\n",
      "\n",
      " [INFO] Round 370\n",
      "\n",
      " [INFO] Round 371\n",
      "\n",
      " [INFO] Round 372\n",
      "\n",
      " [INFO] Round 373\n",
      "\n",
      " [INFO] Round 374\n",
      "\n",
      " [INFO] Round 375\n",
      "\n",
      " [INFO] Round 376\n",
      "\n",
      " [INFO] Round 377\n",
      "\n",
      " [INFO] Round 378\n",
      "\n",
      " [INFO] Round 379\n",
      "\n",
      " [INFO] Round 380\n",
      "Val loss: 0.7245261669158936, Val accuracy: 0.8034640550613403\n",
      "\n",
      " [INFO] Round 381\n",
      "\n",
      " [INFO] Round 382\n",
      "\n",
      " [INFO] Round 383\n",
      "\n",
      " [INFO] Round 384\n",
      "\n",
      " [INFO] Round 385\n",
      "\n",
      " [INFO] Round 386\n",
      "\n",
      " [INFO] Round 387\n",
      "\n",
      " [INFO] Round 388\n",
      "\n",
      " [INFO] Round 389\n",
      "\n",
      " [INFO] Round 390\n",
      "\n",
      " [INFO] Round 391\n",
      "\n",
      " [INFO] Round 392\n",
      "\n",
      " [INFO] Round 393\n",
      "\n",
      " [INFO] Round 394\n",
      "\n",
      " [INFO] Round 395\n",
      "\n",
      " [INFO] Round 396\n",
      "\n",
      " [INFO] Round 397\n",
      "\n",
      " [INFO] Round 398\n",
      "\n",
      " [INFO] Round 399\n",
      "\n",
      " [INFO] Round 400\n",
      "Val loss: 0.7217352986335754, Val accuracy: 0.8029993772506714\n",
      "\n",
      " [INFO] Round 401\n",
      "\n",
      " [INFO] Round 402\n",
      "\n",
      " [INFO] Round 403\n",
      "\n",
      " [INFO] Round 404\n",
      "\n",
      " [INFO] Round 405\n",
      "\n",
      " [INFO] Round 406\n",
      "\n",
      " [INFO] Round 407\n",
      "\n",
      " [INFO] Round 408\n",
      "\n",
      " [INFO] Round 409\n",
      "\n",
      " [INFO] Round 410\n",
      "\n",
      " [INFO] Round 411\n",
      "\n",
      " [INFO] Round 412\n",
      "\n",
      " [INFO] Round 413\n",
      "\n",
      " [INFO] Round 414\n",
      "\n",
      " [INFO] Round 415\n",
      "\n",
      " [INFO] Round 416\n",
      "\n",
      " [INFO] Round 417\n",
      "\n",
      " [INFO] Round 418\n",
      "\n",
      " [INFO] Round 419\n",
      "\n",
      " [INFO] Round 420\n",
      "Val loss: 0.704667329788208, Val accuracy: 0.8044707179069519\n",
      "\n",
      " [INFO] Round 421\n",
      "\n",
      " [INFO] Round 422\n",
      "\n",
      " [INFO] Round 423\n",
      "\n",
      " [INFO] Round 424\n",
      "\n",
      " [INFO] Round 425\n",
      "\n",
      " [INFO] Round 426\n",
      "\n",
      " [INFO] Round 427\n",
      "\n",
      " [INFO] Round 428\n",
      "\n",
      " [INFO] Round 429\n",
      "\n",
      " [INFO] Round 430\n",
      "\n",
      " [INFO] Round 431\n",
      "\n",
      " [INFO] Round 432\n",
      "\n",
      " [INFO] Round 433\n",
      "\n",
      " [INFO] Round 434\n",
      "\n",
      " [INFO] Round 435\n",
      "\n",
      " [INFO] Round 436\n",
      "\n",
      " [INFO] Round 437\n",
      "\n",
      " [INFO] Round 438\n",
      "\n",
      " [INFO] Round 439\n",
      "\n",
      " [INFO] Round 440\n",
      "Val loss: 0.686380922794342, Val accuracy: 0.8078005313873291\n",
      "\n",
      " [INFO] Round 441\n",
      "\n",
      " [INFO] Round 442\n",
      "\n",
      " [INFO] Round 443\n",
      "\n",
      " [INFO] Round 444\n",
      "\n",
      " [INFO] Round 445\n",
      "\n",
      " [INFO] Round 446\n",
      "\n",
      " [INFO] Round 447\n",
      "\n",
      " [INFO] Round 448\n",
      "\n",
      " [INFO] Round 449\n",
      "\n",
      " [INFO] Round 450\n",
      "\n",
      " [INFO] Round 451\n",
      "\n",
      " [INFO] Round 452\n",
      "\n",
      " [INFO] Round 453\n",
      "\n",
      " [INFO] Round 454\n",
      "\n",
      " [INFO] Round 455\n",
      "\n",
      " [INFO] Round 456\n",
      "\n",
      " [INFO] Round 457\n",
      "\n",
      " [INFO] Round 458\n",
      "\n",
      " [INFO] Round 459\n",
      "\n",
      " [INFO] Round 460\n",
      "Val loss: 0.7025101184844971, Val accuracy: 0.8050643801689148\n",
      "\n",
      " [INFO] Round 461\n",
      "\n",
      " [INFO] Round 462\n",
      "\n",
      " [INFO] Round 463\n",
      "\n",
      " [INFO] Round 464\n",
      "\n",
      " [INFO] Round 465\n",
      "\n",
      " [INFO] Round 466\n",
      "\n",
      " [INFO] Round 467\n",
      "\n",
      " [INFO] Round 468\n",
      "\n",
      " [INFO] Round 469\n",
      "\n",
      " [INFO] Round 470\n",
      "\n",
      " [INFO] Round 471\n",
      "\n",
      " [INFO] Round 472\n",
      "\n",
      " [INFO] Round 473\n",
      "\n",
      " [INFO] Round 474\n",
      "\n",
      " [INFO] Round 475\n",
      "\n",
      " [INFO] Round 476\n",
      "\n",
      " [INFO] Round 477\n",
      "\n",
      " [INFO] Round 478\n",
      "\n",
      " [INFO] Round 479\n",
      "\n",
      " [INFO] Round 480\n",
      "Val loss: 0.7042549252510071, Val accuracy: 0.8079295754432678\n",
      "\n",
      " [INFO] Round 481\n",
      "\n",
      " [INFO] Round 482\n",
      "\n",
      " [INFO] Round 483\n",
      "\n",
      " [INFO] Round 484\n",
      "\n",
      " [INFO] Round 485\n",
      "\n",
      " [INFO] Round 486\n",
      "\n",
      " [INFO] Round 487\n",
      "\n",
      " [INFO] Round 488\n",
      "\n",
      " [INFO] Round 489\n",
      "\n",
      " [INFO] Round 490\n",
      "\n",
      " [INFO] Round 491\n",
      "\n",
      " [INFO] Round 492\n",
      "\n",
      " [INFO] Round 493\n",
      "\n",
      " [INFO] Round 494\n",
      "\n",
      " [INFO] Round 495\n",
      "\n",
      " [INFO] Round 496\n",
      "\n",
      " [INFO] Round 497\n",
      "\n",
      " [INFO] Round 498\n",
      "\n",
      " [INFO] Round 499\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = num_clients\n",
    "list_val_acc = []\n",
    "list_val_loss = []\n",
    "\n",
    "\n",
    "for idx_round in range(NUM_ROUNDS):\n",
    "    print(\"\\n [INFO] Round {}\".format(idx_round))\n",
    "\n",
    "    # Load global model at begin of each round.\n",
    "    global_model = keras.models.load_model(PATH_GLOBAL_MODEL)\n",
    "    global_model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics = METRICS)\n",
    "\n",
    "    # Perform the pruning process\n",
    "    if IS_STILL_PRUNE == True:\n",
    "        if idx_round > MAX_PRUNED_ROUND:\n",
    "            IS_STILL_PRUNE = False\n",
    "            print(f\"===== [INFO] Stop prune here. Final params: {global_model.count_params()}\")\n",
    "        elif idx_round > 0:\n",
    "            global_model = prune_model(global_model, optimizer=OPTIMIZER, loss_func=LOSS, metrics=METRICS, std_threshold=STD_THRESHOLD_PRUNE)\n",
    "    \n",
    "    # Clients clone model from server\n",
    "    client_model = keras.models.clone_model(global_model)    \n",
    "    client_model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "    selected_clients_data = random.sample(list_clients_data, NUM_SELECTED_CLIENT)  # Random subset clients\n",
    "\n",
    "    # Loop through selected client\n",
    "    list_client_model_weight = []\n",
    "    list_client_scales = []\n",
    "    for selectd_client_data in selected_clients_data:      \n",
    "        client_model.set_weights(global_model.get_weights())  # Clone global model\n",
    "\n",
    "        list_X = selectd_client_data['list_X']\n",
    "        list_y = selectd_client_data['list_y']\n",
    "        client_model.fit(list_X, list_y, epochs=LOCAL_EPOCHS, batch_size=LOCAL_BATCH_SIZE, verbose=0)\n",
    "\n",
    "        list_client_model_weight.append(client_model.get_weights())    # store local weight for update global model later.\n",
    "        list_client_scales.append(len(list_X))\n",
    "    \n",
    "    # Calculate scale of each client\n",
    "    list_client_scales = np.array(list_client_scales)\n",
    "    list_client_scales = list_client_scales / list_client_scales.sum()\n",
    "\n",
    "    # Update the global model weights\n",
    "    avg_weights = FedAvg(global_model, list_client_model_weight, list_client_scales)\n",
    "    global_model.set_weights(avg_weights)\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    if idx_round % 20 == 0:\n",
    "        val_loss, val_acc = global_model.evaluate(X_val, y_val, verbose=0)\n",
    "        print(f'Val loss: {val_loss}, Val accuracy: {val_acc}')\n",
    "        list_val_acc.append(val_acc)\n",
    "        list_val_loss.append(val_loss)\n",
    "\n",
    "    global_model.save(PATH_GLOBAL_MODEL)\n",
    "    selected_clients_data = None\n",
    "    list_client_model_weight = list_client_scales = None\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X test: (38742, 28, 28, 1)\n",
      "Shape of y test: (38742, 62)\n"
     ]
    }
   ],
   "source": [
    "# X_test = np.array([resize(image, (IMAGE_DIMENSION, IMAGE_DIMENSION)) for image in X_test])\n",
    "print(f\"Shape of X test: {X_test.shape}\")\n",
    "print(f\"Shape of y test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6906054019927979, Val accuracy: 0.8074440956115723\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on testing data\n",
    "val_loss, val_acc = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Val loss: {val_loss}, Val accuracy: {val_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
