{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, I will train the FL with the Inception Architecture on the FEMNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 17:12:00.486507: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-24 17:12:00.486529: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-24 17:12:00.486560: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:  tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e: print(e)\n",
    "\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from config_celeb import *\n",
    "from utils.read_data_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.pruning_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Dataset Hyper-parameter\n",
    "DATASET_NAME = 'mnist'  # mnist\n",
    "\n",
    "IMAGE_DIMENSION = 28\n",
    "INPUT_SHAPE = (IMAGE_DIMENSION, IMAGE_DIMENSION, 1)\n",
    "\n",
    "OUPUT_SHAPE = 62 # \n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Model Hyper-parameter\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS = 'categorical_crossentropy'\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "LIST_NUMBER_FILTERS = [32, 16, 16, 16, 32, 32, 32, 96, 96]\n",
    "FILTER_SIZE = 5\n",
    "\n",
    "MODEL_TYPE = \"inception\" # ['vanilla_conv', 'resnet', 'inception']\n",
    "PATH_GLOBAL_MODEL = os.path.join(\"models\", \"global_model_inception_femnist.h5\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Training Hyper-parameter\n",
    "NUM_ROUNDS = 500\n",
    "NUM_SELECTED_CLIENT = 10\n",
    "\n",
    "LOCAL_EPOCHS = 5\n",
    "LOCAL_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clients: 3400\n"
     ]
    }
   ],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(only_digits=False)\n",
    "\n",
    "num_clients = len(emnist_train.client_ids)\n",
    "print(f\"Number of clients: {num_clients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user: 3400\n"
     ]
    }
   ],
   "source": [
    "list_clients_data = Create_Clients_Data(emnist_train, DATASET_NAME)\n",
    "print(f\"Number of user: {len(list_clients_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image: (28, 28, 1)\n",
      "Max value of X: 1.0\n",
      "Min value of X: 0.038536667823791504\n",
      "Client = f0006_12\n",
      "Label = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_client = np.random.randint(0, 10)\n",
    "idx_sample = np.random.randint(0, 10)\n",
    "\n",
    "client_data = list_clients_data[idx_client]\n",
    "\n",
    "client_name = client_data['client_name']\n",
    "list_X = client_data['list_X']\n",
    "list_y = client_data['list_y']\n",
    "\n",
    "X = list_X[idx_sample]\n",
    "print(f\"Shape of image: {X.shape}\")\n",
    "print(f\"Max value of X: {X.max()}\")\n",
    "print(f\"Min value of X: {X.min()}\")\n",
    "\n",
    "y = list_y[idx_sample]\n",
    "\n",
    "print(f\"Client = {client_name}\")\n",
    "print(f\"Label = {y}\")\n",
    "plt.imshow(X, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Prepare val - test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X val: (38741, 28, 28, 1)\n",
      "Shape of y val: (38741, 62)\n",
      "Shape of X test: (38742, 28, 28, 1)\n",
      "Shape of y test: (38742, 62)\n"
     ]
    }
   ],
   "source": [
    "list_data_test = Create_Clients_Data(emnist_test)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for data_test in list_data_test:\n",
    "    X_test.append(data_test['list_X'])\n",
    "    y_test.append(data_test['list_y'])\n",
    "X_test = np.concatenate(X_test)\n",
    "y_test = np.concatenate(y_test)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Shape of X val: {X_val.shape}\")\n",
    "print(f\"Shape of y val: {y_val.shape}\")\n",
    "\n",
    "print(f\"Shape of X test: {X_test.shape}\")\n",
    "print(f\"Shape of y test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. FL Training\n",
    "\n",
    "## 2.1. Define components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_inception_module_naive(input_tensor, filters_1x1, filters_3x3, filters_5x5, idx_inception_block):\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3}\")(input_tensor)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3+1}\")(input_tensor)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', name=f\"prunable_conv_{1+idx_inception_block*3+2}\")(input_tensor)\n",
    "    output = Concatenate(axis=-1)([conv_1x1, conv_3x3, conv_5x5])\n",
    "    return output\n",
    "\n",
    "def define_inception_model(input_shape, output_shape, list_number_filters):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    X = Conv2D(filters=list_number_filters[0], kernel_size=3, strides=2, activation='relu', name=f'prunable_conv_0')(input_tensor)\n",
    "\n",
    "    for idx_inception_block in range(1, len(list_number_filters) - 2, 3):\n",
    "        list_current_filters = list_number_filters[idx_inception_block:idx_inception_block+3]\n",
    "        filters_1x1, filters_3x3, filters_5x5 = list_current_filters\n",
    "        X = my_inception_module_naive(X, filters_1x1, filters_3x3, filters_5x5, idx_inception_block-1)\n",
    "\n",
    "    X = Conv2D(filters=list_number_filters[-2], kernel_size=3, strides=2, activation='relu', name=f'prunable_conv_6')(X)\n",
    "    X = Conv2D(filters=list_number_filters[-1], kernel_size=3, strides=2, activation='relu', name=f'prunable_conv_7')(X)\n",
    "\n",
    "    # X = Flatten()(X)\n",
    "    X = GlobalAveragePooling2D()(X)\n",
    "\n",
    "    X = Dense(50, activation='relu')(X)\n",
    "    X = Dense(output_shape, activation='softmax')(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 246236\n",
      "Number of Conv2D layer: 9\n",
      "FLOPS of global model: 31010894\n",
      "=========================Options=============================\n",
      "\n",
      "Model: \"model\"\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "op: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "Conv2D                   30.96m float_ops (100.00%, 99.84%)\n",
      "BiasAdd                  33.70k float_ops (0.16%, 0.11%)\n",
      "MatMul                   15.80k float_ops (0.05%, 0.05%)\n",
      "Mean                       384 float_ops (0.00%, 0.00%)\n",
      "Softmax                    310 float_ops (0.00%, 0.00%)\n",
      "\n",
      "======================End of Report==========================\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " prunable_conv_0 (Conv2D)    (None, 13, 13, 32)           320       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " prunable_conv_1 (Conv2D)    (None, 13, 13, 16)           528       ['prunable_conv_0[0][0]']     \n",
      "                                                                                                  \n",
      " prunable_conv_2 (Conv2D)    (None, 13, 13, 16)           4624      ['prunable_conv_0[0][0]']     \n",
      "                                                                                                  \n",
      " prunable_conv_3 (Conv2D)    (None, 13, 13, 16)           12816     ['prunable_conv_0[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 13, 13, 48)           0         ['prunable_conv_1[0][0]',     \n",
      "                                                                     'prunable_conv_2[0][0]',     \n",
      "                                                                     'prunable_conv_3[0][0]']     \n",
      "                                                                                                  \n",
      " prunable_conv_10 (Conv2D)   (None, 13, 13, 32)           1568      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " prunable_conv_11 (Conv2D)   (None, 13, 13, 32)           13856     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " prunable_conv_12 (Conv2D)   (None, 13, 13, 32)           38432     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 13, 13, 96)           0         ['prunable_conv_10[0][0]',    \n",
      " )                                                                   'prunable_conv_11[0][0]',    \n",
      "                                                                     'prunable_conv_12[0][0]']    \n",
      "                                                                                                  \n",
      " prunable_conv_6 (Conv2D)    (None, 6, 6, 96)             83040     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " prunable_conv_7 (Conv2D)    (None, 2, 2, 96)             83040     ['prunable_conv_6[0][0]']     \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 96)                   0         ['prunable_conv_7[0][0]']     \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 50)                   4850      ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 62)                   3162      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 246236 (961.86 KB)\n",
      "Trainable params: 246236 (961.86 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "global_model = define_inception_model(INPUT_SHAPE, OUPUT_SHAPE, LIST_NUMBER_FILTERS)\n",
    "global_model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics = METRICS)\n",
    "print(f\"Number of params: {global_model.count_params()}\")\n",
    "\n",
    "num_conv_layers = Count_Conv2d_Layers(global_model)\n",
    "print(f\"Number of Conv2D layer: {num_conv_layers}\")\n",
    "plot_model(global_model, to_file=os.path.join('images', f'{MODEL_TYPE}.png'), show_shapes=True, show_layer_names=True);\n",
    "global_model.save(PATH_GLOBAL_MODEL)\n",
    "\n",
    "flops = get_flops_keras_model(global_model)\n",
    "print(f\"FLOPS of global model: {flops}\")\n",
    "\n",
    "global_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. FL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Round 0\n",
      "Val loss: 3.9832804203033447, Val accuracy: 0.035053301602602005\n",
      "\n",
      " [INFO] Round 1\n",
      "\n",
      " [INFO] Round 2\n",
      "\n",
      " [INFO] Round 3\n",
      "\n",
      " [INFO] Round 4\n",
      "\n",
      " [INFO] Round 5\n",
      "\n",
      " [INFO] Round 6\n",
      "\n",
      " [INFO] Round 7\n",
      "\n",
      " [INFO] Round 8\n",
      "\n",
      " [INFO] Round 9\n",
      "\n",
      " [INFO] Round 10\n",
      "\n",
      " [INFO] Round 11\n",
      "\n",
      " [INFO] Round 12\n",
      "\n",
      " [INFO] Round 13\n",
      "\n",
      " [INFO] Round 14\n",
      "\n",
      " [INFO] Round 15\n",
      "\n",
      " [INFO] Round 16\n",
      "\n",
      " [INFO] Round 17\n",
      "\n",
      " [INFO] Round 18\n",
      "\n",
      " [INFO] Round 19\n",
      "\n",
      " [INFO] Round 20\n",
      "Val loss: 1.6455457210540771, Val accuracy: 0.5863813757896423\n",
      "\n",
      " [INFO] Round 21\n",
      "\n",
      " [INFO] Round 22\n",
      "\n",
      " [INFO] Round 23\n",
      "\n",
      " [INFO] Round 24\n",
      "\n",
      " [INFO] Round 25\n",
      "\n",
      " [INFO] Round 26\n",
      "\n",
      " [INFO] Round 27\n",
      "\n",
      " [INFO] Round 28\n",
      "\n",
      " [INFO] Round 29\n",
      "\n",
      " [INFO] Round 30\n",
      "\n",
      " [INFO] Round 31\n",
      "\n",
      " [INFO] Round 32\n",
      "\n",
      " [INFO] Round 33\n",
      "\n",
      " [INFO] Round 34\n",
      "\n",
      " [INFO] Round 35\n",
      "\n",
      " [INFO] Round 36\n",
      "\n",
      " [INFO] Round 37\n",
      "\n",
      " [INFO] Round 38\n",
      "\n",
      " [INFO] Round 39\n",
      "\n",
      " [INFO] Round 40\n",
      "Val loss: 1.3099329471588135, Val accuracy: 0.6754601001739502\n",
      "\n",
      " [INFO] Round 41\n",
      "\n",
      " [INFO] Round 42\n",
      "\n",
      " [INFO] Round 43\n",
      "\n",
      " [INFO] Round 44\n",
      "\n",
      " [INFO] Round 45\n",
      "\n",
      " [INFO] Round 46\n",
      "\n",
      " [INFO] Round 47\n",
      "\n",
      " [INFO] Round 48\n",
      "\n",
      " [INFO] Round 49\n",
      "\n",
      " [INFO] Round 50\n",
      "\n",
      " [INFO] Round 51\n",
      "\n",
      " [INFO] Round 52\n",
      "\n",
      " [INFO] Round 53\n",
      "\n",
      " [INFO] Round 54\n",
      "\n",
      " [INFO] Round 55\n",
      "\n",
      " [INFO] Round 56\n",
      "\n",
      " [INFO] Round 57\n",
      "\n",
      " [INFO] Round 58\n",
      "\n",
      " [INFO] Round 59\n",
      "\n",
      " [INFO] Round 60\n",
      "Val loss: 1.121439814567566, Val accuracy: 0.7001109719276428\n",
      "\n",
      " [INFO] Round 61\n",
      "\n",
      " [INFO] Round 62\n",
      "\n",
      " [INFO] Round 63\n",
      "\n",
      " [INFO] Round 64\n",
      "\n",
      " [INFO] Round 65\n",
      "\n",
      " [INFO] Round 66\n",
      "\n",
      " [INFO] Round 67\n",
      "\n",
      " [INFO] Round 68\n",
      "\n",
      " [INFO] Round 69\n",
      "\n",
      " [INFO] Round 70\n",
      "\n",
      " [INFO] Round 71\n",
      "\n",
      " [INFO] Round 72\n",
      "\n",
      " [INFO] Round 73\n",
      "\n",
      " [INFO] Round 74\n",
      "\n",
      " [INFO] Round 75\n",
      "\n",
      " [INFO] Round 76\n",
      "\n",
      " [INFO] Round 77\n",
      "\n",
      " [INFO] Round 78\n",
      "\n",
      " [INFO] Round 79\n",
      "\n",
      " [INFO] Round 80\n",
      "Val loss: 1.0071558952331543, Val accuracy: 0.7386231422424316\n",
      "\n",
      " [INFO] Round 81\n",
      "\n",
      " [INFO] Round 82\n",
      "\n",
      " [INFO] Round 83\n",
      "\n",
      " [INFO] Round 84\n",
      "\n",
      " [INFO] Round 85\n",
      "\n",
      " [INFO] Round 86\n",
      "\n",
      " [INFO] Round 87\n",
      "\n",
      " [INFO] Round 88\n",
      "\n",
      " [INFO] Round 89\n",
      "\n",
      " [INFO] Round 90\n",
      "\n",
      " [INFO] Round 91\n",
      "\n",
      " [INFO] Round 92\n",
      "\n",
      " [INFO] Round 93\n",
      "\n",
      " [INFO] Round 94\n",
      "\n",
      " [INFO] Round 95\n",
      "\n",
      " [INFO] Round 96\n",
      "\n",
      " [INFO] Round 97\n",
      "\n",
      " [INFO] Round 98\n",
      "\n",
      " [INFO] Round 99\n",
      "\n",
      " [INFO] Round 100\n",
      "Val loss: 0.8921584486961365, Val accuracy: 0.7582148313522339\n",
      "\n",
      " [INFO] Round 101\n",
      "\n",
      " [INFO] Round 102\n",
      "\n",
      " [INFO] Round 103\n",
      "\n",
      " [INFO] Round 104\n",
      "\n",
      " [INFO] Round 105\n",
      "\n",
      " [INFO] Round 106\n",
      "\n",
      " [INFO] Round 107\n",
      "\n",
      " [INFO] Round 108\n",
      "\n",
      " [INFO] Round 109\n",
      "\n",
      " [INFO] Round 110\n",
      "\n",
      " [INFO] Round 111\n",
      "\n",
      " [INFO] Round 112\n",
      "\n",
      " [INFO] Round 113\n",
      "\n",
      " [INFO] Round 114\n",
      "\n",
      " [INFO] Round 115\n",
      "\n",
      " [INFO] Round 116\n",
      "\n",
      " [INFO] Round 117\n",
      "\n",
      " [INFO] Round 118\n",
      "\n",
      " [INFO] Round 119\n",
      "\n",
      " [INFO] Round 120\n",
      "Val loss: 1.0021551847457886, Val accuracy: 0.7446116805076599\n",
      "\n",
      " [INFO] Round 121\n",
      "\n",
      " [INFO] Round 122\n",
      "\n",
      " [INFO] Round 123\n",
      "\n",
      " [INFO] Round 124\n",
      "\n",
      " [INFO] Round 125\n",
      "\n",
      " [INFO] Round 126\n",
      "\n",
      " [INFO] Round 127\n",
      "\n",
      " [INFO] Round 128\n",
      "\n",
      " [INFO] Round 129\n",
      "\n",
      " [INFO] Round 130\n",
      "\n",
      " [INFO] Round 131\n",
      "\n",
      " [INFO] Round 132\n",
      "\n",
      " [INFO] Round 133\n",
      "\n",
      " [INFO] Round 134\n",
      "\n",
      " [INFO] Round 135\n",
      "\n",
      " [INFO] Round 136\n",
      "\n",
      " [INFO] Round 137\n",
      "\n",
      " [INFO] Round 138\n",
      "\n",
      " [INFO] Round 139\n",
      "\n",
      " [INFO] Round 140\n",
      "Val loss: 0.8670750856399536, Val accuracy: 0.7821429371833801\n",
      "\n",
      " [INFO] Round 141\n",
      "\n",
      " [INFO] Round 142\n",
      "\n",
      " [INFO] Round 143\n",
      "\n",
      " [INFO] Round 144\n",
      "\n",
      " [INFO] Round 145\n",
      "\n",
      " [INFO] Round 146\n",
      "\n",
      " [INFO] Round 147\n",
      "\n",
      " [INFO] Round 148\n",
      "\n",
      " [INFO] Round 149\n",
      "\n",
      " [INFO] Round 150\n",
      "\n",
      " [INFO] Round 151\n",
      "\n",
      " [INFO] Round 152\n",
      "\n",
      " [INFO] Round 153\n",
      "\n",
      " [INFO] Round 154\n",
      "\n",
      " [INFO] Round 155\n",
      "\n",
      " [INFO] Round 156\n",
      "\n",
      " [INFO] Round 157\n",
      "\n",
      " [INFO] Round 158\n",
      "\n",
      " [INFO] Round 159\n",
      "\n",
      " [INFO] Round 160\n",
      "Val loss: 0.8130910396575928, Val accuracy: 0.7800005078315735\n",
      "\n",
      " [INFO] Round 161\n",
      "\n",
      " [INFO] Round 162\n",
      "\n",
      " [INFO] Round 163\n",
      "\n",
      " [INFO] Round 164\n",
      "\n",
      " [INFO] Round 165\n",
      "\n",
      " [INFO] Round 166\n",
      "\n",
      " [INFO] Round 167\n",
      "\n",
      " [INFO] Round 168\n",
      "\n",
      " [INFO] Round 169\n",
      "\n",
      " [INFO] Round 170\n",
      "\n",
      " [INFO] Round 171\n",
      "\n",
      " [INFO] Round 172\n",
      "\n",
      " [INFO] Round 173\n",
      "\n",
      " [INFO] Round 174\n",
      "\n",
      " [INFO] Round 175\n",
      "\n",
      " [INFO] Round 176\n",
      "\n",
      " [INFO] Round 177\n",
      "\n",
      " [INFO] Round 178\n",
      "\n",
      " [INFO] Round 179\n",
      "\n",
      " [INFO] Round 180\n",
      "Val loss: 0.7442979216575623, Val accuracy: 0.7916677594184875\n",
      "\n",
      " [INFO] Round 181\n",
      "\n",
      " [INFO] Round 182\n",
      "\n",
      " [INFO] Round 183\n",
      "\n",
      " [INFO] Round 184\n",
      "\n",
      " [INFO] Round 185\n",
      "\n",
      " [INFO] Round 186\n",
      "\n",
      " [INFO] Round 187\n",
      "\n",
      " [INFO] Round 188\n",
      "\n",
      " [INFO] Round 189\n",
      "\n",
      " [INFO] Round 190\n",
      "\n",
      " [INFO] Round 191\n",
      "\n",
      " [INFO] Round 192\n",
      "\n",
      " [INFO] Round 193\n",
      "\n",
      " [INFO] Round 194\n",
      "\n",
      " [INFO] Round 195\n",
      "\n",
      " [INFO] Round 196\n",
      "\n",
      " [INFO] Round 197\n",
      "\n",
      " [INFO] Round 198\n",
      "\n",
      " [INFO] Round 199\n",
      "\n",
      " [INFO] Round 200\n",
      "Val loss: 0.8004357814788818, Val accuracy: 0.7968302369117737\n",
      "\n",
      " [INFO] Round 201\n",
      "\n",
      " [INFO] Round 202\n",
      "\n",
      " [INFO] Round 203\n",
      "\n",
      " [INFO] Round 204\n",
      "\n",
      " [INFO] Round 205\n",
      "\n",
      " [INFO] Round 206\n",
      "\n",
      " [INFO] Round 207\n",
      "\n",
      " [INFO] Round 208\n",
      "\n",
      " [INFO] Round 209\n",
      "\n",
      " [INFO] Round 210\n",
      "\n",
      " [INFO] Round 211\n",
      "\n",
      " [INFO] Round 212\n",
      "\n",
      " [INFO] Round 213\n",
      "\n",
      " [INFO] Round 214\n",
      "\n",
      " [INFO] Round 215\n",
      "\n",
      " [INFO] Round 216\n",
      "\n",
      " [INFO] Round 217\n",
      "\n",
      " [INFO] Round 218\n",
      "\n",
      " [INFO] Round 219\n",
      "\n",
      " [INFO] Round 220\n",
      "Val loss: 0.7824982404708862, Val accuracy: 0.7956170439720154\n",
      "\n",
      " [INFO] Round 221\n",
      "\n",
      " [INFO] Round 222\n",
      "\n",
      " [INFO] Round 223\n",
      "\n",
      " [INFO] Round 224\n",
      "\n",
      " [INFO] Round 225\n",
      "\n",
      " [INFO] Round 226\n",
      "\n",
      " [INFO] Round 227\n",
      "\n",
      " [INFO] Round 228\n",
      "\n",
      " [INFO] Round 229\n",
      "\n",
      " [INFO] Round 230\n",
      "\n",
      " [INFO] Round 231\n",
      "\n",
      " [INFO] Round 232\n",
      "\n",
      " [INFO] Round 233\n",
      "\n",
      " [INFO] Round 234\n",
      "\n",
      " [INFO] Round 235\n",
      "\n",
      " [INFO] Round 236\n",
      "\n",
      " [INFO] Round 237\n",
      "\n",
      " [INFO] Round 238\n",
      "\n",
      " [INFO] Round 239\n",
      "\n",
      " [INFO] Round 240\n",
      "Val loss: 0.7217087149620056, Val accuracy: 0.8115175366401672\n",
      "\n",
      " [INFO] Round 241\n",
      "\n",
      " [INFO] Round 242\n",
      "\n",
      " [INFO] Round 243\n",
      "\n",
      " [INFO] Round 244\n",
      "\n",
      " [INFO] Round 245\n",
      "\n",
      " [INFO] Round 246\n",
      "\n",
      " [INFO] Round 247\n",
      "\n",
      " [INFO] Round 248\n",
      "\n",
      " [INFO] Round 249\n",
      "\n",
      " [INFO] Round 250\n",
      "\n",
      " [INFO] Round 251\n",
      "\n",
      " [INFO] Round 252\n",
      "\n",
      " [INFO] Round 253\n",
      "\n",
      " [INFO] Round 254\n",
      "\n",
      " [INFO] Round 255\n",
      "\n",
      " [INFO] Round 256\n",
      "\n",
      " [INFO] Round 257\n",
      "\n",
      " [INFO] Round 258\n",
      "\n",
      " [INFO] Round 259\n",
      "\n",
      " [INFO] Round 260\n",
      "Val loss: 0.703179121017456, Val accuracy: 0.8112077713012695\n",
      "\n",
      " [INFO] Round 261\n",
      "\n",
      " [INFO] Round 262\n",
      "\n",
      " [INFO] Round 263\n",
      "\n",
      " [INFO] Round 264\n",
      "\n",
      " [INFO] Round 265\n",
      "\n",
      " [INFO] Round 266\n",
      "\n",
      " [INFO] Round 267\n",
      "\n",
      " [INFO] Round 268\n",
      "\n",
      " [INFO] Round 269\n",
      "\n",
      " [INFO] Round 270\n",
      "\n",
      " [INFO] Round 271\n",
      "\n",
      " [INFO] Round 272\n",
      "\n",
      " [INFO] Round 273\n",
      "\n",
      " [INFO] Round 274\n",
      "\n",
      " [INFO] Round 275\n",
      "\n",
      " [INFO] Round 276\n",
      "\n",
      " [INFO] Round 277\n",
      "\n",
      " [INFO] Round 278\n",
      "\n",
      " [INFO] Round 279\n",
      "\n",
      " [INFO] Round 280\n",
      "Val loss: 0.6813147664070129, Val accuracy: 0.8114400506019592\n",
      "\n",
      " [INFO] Round 281\n",
      "\n",
      " [INFO] Round 282\n",
      "\n",
      " [INFO] Round 283\n",
      "\n",
      " [INFO] Round 284\n",
      "\n",
      " [INFO] Round 285\n",
      "\n",
      " [INFO] Round 286\n",
      "\n",
      " [INFO] Round 287\n",
      "\n",
      " [INFO] Round 288\n",
      "\n",
      " [INFO] Round 289\n",
      "\n",
      " [INFO] Round 290\n",
      "\n",
      " [INFO] Round 291\n",
      "\n",
      " [INFO] Round 292\n",
      "\n",
      " [INFO] Round 293\n",
      "\n",
      " [INFO] Round 294\n",
      "\n",
      " [INFO] Round 295\n",
      "\n",
      " [INFO] Round 296\n",
      "\n",
      " [INFO] Round 297\n",
      "\n",
      " [INFO] Round 298\n",
      "\n",
      " [INFO] Round 299\n",
      "\n",
      " [INFO] Round 300\n",
      "Val loss: 0.7391253709793091, Val accuracy: 0.8032317161560059\n",
      "\n",
      " [INFO] Round 301\n",
      "\n",
      " [INFO] Round 302\n",
      "\n",
      " [INFO] Round 303\n",
      "\n",
      " [INFO] Round 304\n",
      "\n",
      " [INFO] Round 305\n",
      "\n",
      " [INFO] Round 306\n",
      "\n",
      " [INFO] Round 307\n",
      "\n",
      " [INFO] Round 308\n",
      "\n",
      " [INFO] Round 309\n",
      "\n",
      " [INFO] Round 310\n",
      "\n",
      " [INFO] Round 311\n",
      "\n",
      " [INFO] Round 312\n",
      "\n",
      " [INFO] Round 313\n",
      "\n",
      " [INFO] Round 314\n",
      "\n",
      " [INFO] Round 315\n",
      "\n",
      " [INFO] Round 316\n",
      "\n",
      " [INFO] Round 317\n",
      "\n",
      " [INFO] Round 318\n",
      "\n",
      " [INFO] Round 319\n",
      "\n",
      " [INFO] Round 320\n",
      "Val loss: 0.6292127966880798, Val accuracy: 0.8190031051635742\n",
      "\n",
      " [INFO] Round 321\n",
      "\n",
      " [INFO] Round 322\n",
      "\n",
      " [INFO] Round 323\n",
      "\n",
      " [INFO] Round 324\n",
      "\n",
      " [INFO] Round 325\n",
      "\n",
      " [INFO] Round 326\n",
      "\n",
      " [INFO] Round 327\n",
      "\n",
      " [INFO] Round 328\n",
      "\n",
      " [INFO] Round 329\n",
      "\n",
      " [INFO] Round 330\n",
      "\n",
      " [INFO] Round 331\n",
      "\n",
      " [INFO] Round 332\n",
      "\n",
      " [INFO] Round 333\n",
      "\n",
      " [INFO] Round 334\n",
      "\n",
      " [INFO] Round 335\n",
      "\n",
      " [INFO] Round 336\n",
      "\n",
      " [INFO] Round 337\n",
      "\n",
      " [INFO] Round 338\n",
      "\n",
      " [INFO] Round 339\n",
      "\n",
      " [INFO] Round 340\n",
      "Val loss: 0.6491400599479675, Val accuracy: 0.8074649572372437\n",
      "\n",
      " [INFO] Round 341\n",
      "\n",
      " [INFO] Round 342\n",
      "\n",
      " [INFO] Round 343\n",
      "\n",
      " [INFO] Round 344\n",
      "\n",
      " [INFO] Round 345\n",
      "\n",
      " [INFO] Round 346\n",
      "\n",
      " [INFO] Round 347\n",
      "\n",
      " [INFO] Round 348\n",
      "\n",
      " [INFO] Round 349\n",
      "\n",
      " [INFO] Round 350\n",
      "\n",
      " [INFO] Round 351\n",
      "\n",
      " [INFO] Round 352\n",
      "\n",
      " [INFO] Round 353\n",
      "\n",
      " [INFO] Round 354\n",
      "\n",
      " [INFO] Round 355\n",
      "\n",
      " [INFO] Round 356\n",
      "\n",
      " [INFO] Round 357\n",
      "\n",
      " [INFO] Round 358\n",
      "\n",
      " [INFO] Round 359\n",
      "\n",
      " [INFO] Round 360\n",
      "Val loss: 0.6393387317657471, Val accuracy: 0.8222813010215759\n",
      "\n",
      " [INFO] Round 361\n",
      "\n",
      " [INFO] Round 362\n",
      "\n",
      " [INFO] Round 363\n",
      "\n",
      " [INFO] Round 364\n",
      "\n",
      " [INFO] Round 365\n",
      "\n",
      " [INFO] Round 366\n",
      "\n",
      " [INFO] Round 367\n",
      "\n",
      " [INFO] Round 368\n",
      "\n",
      " [INFO] Round 369\n",
      "\n",
      " [INFO] Round 370\n",
      "\n",
      " [INFO] Round 371\n",
      "\n",
      " [INFO] Round 372\n",
      "\n",
      " [INFO] Round 373\n",
      "\n",
      " [INFO] Round 374\n",
      "\n",
      " [INFO] Round 375\n",
      "\n",
      " [INFO] Round 376\n",
      "\n",
      " [INFO] Round 377\n",
      "\n",
      " [INFO] Round 378\n",
      "\n",
      " [INFO] Round 379\n",
      "\n",
      " [INFO] Round 380\n",
      "Val loss: 0.6973696947097778, Val accuracy: 0.7959784269332886\n",
      "\n",
      " [INFO] Round 381\n",
      "\n",
      " [INFO] Round 382\n",
      "\n",
      " [INFO] Round 383\n",
      "\n",
      " [INFO] Round 384\n",
      "\n",
      " [INFO] Round 385\n",
      "\n",
      " [INFO] Round 386\n",
      "\n",
      " [INFO] Round 387\n",
      "\n",
      " [INFO] Round 388\n",
      "\n",
      " [INFO] Round 389\n",
      "\n",
      " [INFO] Round 390\n",
      "\n",
      " [INFO] Round 391\n",
      "\n",
      " [INFO] Round 392\n",
      "\n",
      " [INFO] Round 393\n",
      "\n",
      " [INFO] Round 394\n",
      "\n",
      " [INFO] Round 395\n",
      "\n",
      " [INFO] Round 396\n",
      "\n",
      " [INFO] Round 397\n",
      "\n",
      " [INFO] Round 398\n",
      "\n",
      " [INFO] Round 399\n",
      "\n",
      " [INFO] Round 400\n",
      "Val loss: 0.6771466135978699, Val accuracy: 0.8006504774093628\n",
      "\n",
      " [INFO] Round 401\n",
      "\n",
      " [INFO] Round 402\n",
      "\n",
      " [INFO] Round 403\n",
      "\n",
      " [INFO] Round 404\n",
      "\n",
      " [INFO] Round 405\n",
      "\n",
      " [INFO] Round 406\n",
      "\n",
      " [INFO] Round 407\n",
      "\n",
      " [INFO] Round 408\n",
      "\n",
      " [INFO] Round 409\n",
      "\n",
      " [INFO] Round 410\n",
      "\n",
      " [INFO] Round 411\n",
      "\n",
      " [INFO] Round 412\n",
      "\n",
      " [INFO] Round 413\n",
      "\n",
      " [INFO] Round 414\n",
      "\n",
      " [INFO] Round 415\n",
      "\n",
      " [INFO] Round 416\n",
      "\n",
      " [INFO] Round 417\n",
      "\n",
      " [INFO] Round 418\n",
      "\n",
      " [INFO] Round 419\n",
      "\n",
      " [INFO] Round 420\n",
      "Val loss: 0.6023443341255188, Val accuracy: 0.8243463039398193\n",
      "\n",
      " [INFO] Round 421\n",
      "\n",
      " [INFO] Round 422\n",
      "\n",
      " [INFO] Round 423\n",
      "\n",
      " [INFO] Round 424\n",
      "\n",
      " [INFO] Round 425\n",
      "\n",
      " [INFO] Round 426\n",
      "\n",
      " [INFO] Round 427\n",
      "\n",
      " [INFO] Round 428\n",
      "\n",
      " [INFO] Round 429\n",
      "\n",
      " [INFO] Round 430\n",
      "\n",
      " [INFO] Round 431\n",
      "\n",
      " [INFO] Round 432\n",
      "\n",
      " [INFO] Round 433\n",
      "\n",
      " [INFO] Round 434\n",
      "\n",
      " [INFO] Round 435\n",
      "\n",
      " [INFO] Round 436\n",
      "\n",
      " [INFO] Round 437\n",
      "\n",
      " [INFO] Round 438\n",
      "\n",
      " [INFO] Round 439\n",
      "\n",
      " [INFO] Round 440\n",
      "Val loss: 0.6913535594940186, Val accuracy: 0.7923646569252014\n",
      "\n",
      " [INFO] Round 441\n",
      "\n",
      " [INFO] Round 442\n",
      "\n",
      " [INFO] Round 443\n",
      "\n",
      " [INFO] Round 444\n",
      "\n",
      " [INFO] Round 445\n",
      "\n",
      " [INFO] Round 446\n",
      "\n",
      " [INFO] Round 447\n",
      "\n",
      " [INFO] Round 448\n",
      "\n",
      " [INFO] Round 449\n",
      "\n",
      " [INFO] Round 450\n",
      "\n",
      " [INFO] Round 451\n",
      "\n",
      " [INFO] Round 452\n",
      "\n",
      " [INFO] Round 453\n",
      "\n",
      " [INFO] Round 454\n",
      "\n",
      " [INFO] Round 455\n",
      "\n",
      " [INFO] Round 456\n",
      "\n",
      " [INFO] Round 457\n",
      "\n",
      " [INFO] Round 458\n",
      "\n",
      " [INFO] Round 459\n",
      "\n",
      " [INFO] Round 460\n",
      "Val loss: 0.6132240891456604, Val accuracy: 0.8250690698623657\n",
      "\n",
      " [INFO] Round 461\n",
      "\n",
      " [INFO] Round 462\n",
      "\n",
      " [INFO] Round 463\n",
      "\n",
      " [INFO] Round 464\n",
      "\n",
      " [INFO] Round 465\n",
      "\n",
      " [INFO] Round 466\n",
      "\n",
      " [INFO] Round 467\n",
      "\n",
      " [INFO] Round 468\n",
      "\n",
      " [INFO] Round 469\n",
      "\n",
      " [INFO] Round 470\n",
      "\n",
      " [INFO] Round 471\n",
      "\n",
      " [INFO] Round 472\n",
      "\n",
      " [INFO] Round 473\n",
      "\n",
      " [INFO] Round 474\n",
      "\n",
      " [INFO] Round 475\n",
      "\n",
      " [INFO] Round 476\n",
      "\n",
      " [INFO] Round 477\n",
      "\n",
      " [INFO] Round 478\n",
      "\n",
      " [INFO] Round 479\n",
      "\n",
      " [INFO] Round 480\n",
      "Val loss: 0.6515046954154968, Val accuracy: 0.8187450170516968\n",
      "\n",
      " [INFO] Round 481\n",
      "\n",
      " [INFO] Round 482\n",
      "\n",
      " [INFO] Round 483\n",
      "\n",
      " [INFO] Round 484\n",
      "\n",
      " [INFO] Round 485\n",
      "\n",
      " [INFO] Round 486\n",
      "\n",
      " [INFO] Round 487\n",
      "\n",
      " [INFO] Round 488\n",
      "\n",
      " [INFO] Round 489\n",
      "\n",
      " [INFO] Round 490\n",
      "\n",
      " [INFO] Round 491\n",
      "\n",
      " [INFO] Round 492\n",
      "\n",
      " [INFO] Round 493\n",
      "\n",
      " [INFO] Round 494\n",
      "\n",
      " [INFO] Round 495\n",
      "\n",
      " [INFO] Round 496\n",
      "\n",
      " [INFO] Round 497\n",
      "\n",
      " [INFO] Round 498\n",
      "\n",
      " [INFO] Round 499\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = num_clients\n",
    "list_val_acc = []\n",
    "list_val_loss = []\n",
    "\n",
    "\n",
    "for idx_round in range(NUM_ROUNDS):\n",
    "    print(\"\\n [INFO] Round {}\".format(idx_round))\n",
    "\n",
    "    # Load global model at begin of each round.\n",
    "    global_model = keras.models.load_model(PATH_GLOBAL_MODEL)\n",
    "    global_model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics = METRICS)\n",
    "    \n",
    "    # Clients clone model from server\n",
    "    client_model = keras.models.clone_model(global_model)    \n",
    "    client_model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "    selected_clients_data = random.sample(list_clients_data, NUM_SELECTED_CLIENT)  # Random subset clients\n",
    "\n",
    "    # Loop through selected client\n",
    "    list_client_model_weight = []\n",
    "    list_client_scales = []\n",
    "    for selectd_client_data in selected_clients_data:      \n",
    "        client_model.set_weights(global_model.get_weights())  # Clone global model\n",
    "\n",
    "        list_X = selectd_client_data['list_X']\n",
    "        list_y = selectd_client_data['list_y']\n",
    "        client_model.fit(list_X, list_y, epochs=LOCAL_EPOCHS, batch_size=LOCAL_BATCH_SIZE, verbose=0)\n",
    "\n",
    "        list_client_model_weight.append(client_model.get_weights())    # store local weight for update global model later.\n",
    "        list_client_scales.append(len(list_X))\n",
    "    \n",
    "    # Calculate scale of each client\n",
    "    list_client_scales = np.array(list_client_scales)\n",
    "    list_client_scales = list_client_scales / list_client_scales.sum()\n",
    "\n",
    "    # Update the global model weights\n",
    "    avg_weights = FedAvg(global_model, list_client_model_weight, list_client_scales)\n",
    "    global_model.set_weights(avg_weights)\n",
    "\n",
    "    # Evaluate model on validation data\n",
    "    if idx_round % 20 == 0:\n",
    "        val_loss, val_acc = global_model.evaluate(X_val, y_val, verbose=0)\n",
    "        print(f'Val loss: {val_loss}, Val accuracy: {val_acc}')\n",
    "        list_val_acc.append(val_acc)\n",
    "        list_val_loss.append(val_loss)\n",
    "\n",
    "    global_model.save(PATH_GLOBAL_MODEL)\n",
    "    selected_clients_data = None\n",
    "    list_client_model_weight = list_client_scales = None\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X test: (38742, 28, 28, 1)\n",
      "Shape of y test: (38742, 62)\n"
     ]
    }
   ],
   "source": [
    "# X_test = np.array([resize(image, (IMAGE_DIMENSION, IMAGE_DIMENSION)) for image in X_test])\n",
    "print(f\"Shape of X test: {X_test.shape}\")\n",
    "print(f\"Shape of y test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7001376152038574, Val accuracy: 0.8219761252403259\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on testing data\n",
    "val_loss, val_acc = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Val loss: {val_loss}, Val accuracy: {val_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
